---
title: "Fuzzy sets"
abstract: >
  Describes the fuzzy sets, interpretation and how to work with them.
output:
  html_document:
    fig_caption: true
    code_folding: show
    self_contained: yes
    toc_float:
      collapsed: true
      toc_depth: 3
author:
- name: LluÃ­s Revilla
  affiliation: 
    - August Pi i Sunyer Biomedical Research Institute (IDIBAPS); Liver Unit, Hospital Clinic
  email: lluis.revilla@gmail.com
vignette: >
  %\VignetteIndexEntry{Fuzzy sets}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, message=FALSE, warning=FALSE, include=FALSE}
knitr::opts_knit$set(root.dir = ".")
knitr::opts_chunk$set(collapse = TRUE, 
                      warning = TRUE,
                      comment = "#>")
library("BaseSet")
library("dplyr")
```


# Getting started

This vignettes supposes that you already read the "About Set" vignette
This vignette explains what are the fuzzy sets and how to use them. 
As all methods for "normal" sets are available for fuzzy sets this vignette focuses on how to create, use them.


# Creating a fuzzy set


To create a fuzzy set you need to have a column named "fuzzy" if you create it 
from a data.frame. This column is restricted to a numeric value between 0 and 1. 
The value indicates the strength (or probability) of the relationship between 
the element and the set. 

```{r fuzzy}
set.seed(4567) # To be able to have exact replicates
relations <- data.frame(sets = c(rep("A", 5), "B", "C"),
                          elements = c(letters[seq_len(6)], letters[6]),
                          fuzzy = runif(7))
fuzzy_set <- tidySet(relations)
```


# Working with fuzzy sets

We can work with fuzzy sets as we do with normal sets. But if you remember that at the end of the vignette we used an Important column now this is already included, which allows us to use this information for union and intersection methods:

## Union

You can make a union of two sets present on the same object.

```{r union}
BaseSet::union(fuzzy_set, sets = c("C", "B"), name = "D")
BaseSet::union(fuzzy_set, sets = c("C", "B"), name =  "D", FUN = "mean")
```

Observe the fuzziness on the resulting set has changed (on the traditional sets it doesn't matter)

## Intersection

We can do the same with the intersection

```{r intersection}
intersection(fuzzy_set, sets = c("A", "B"), keep = FALSE)
intersection(fuzzy_set, sets = c("A", "B"), keep = FALSE, FUN = "mean")
```

But in this example we don't see any difference on the calculated values.

## Complement

We can look for the complement of one or several sets:

```{r complement}
complement_set(fuzzy_set, sets = "A", keep = FALSE)
```

Note that the values of the complement are `1-fuzzy`:

```{r complement_previous}
fuzzy_set %>% filter(sets == "A")
```

## Subtract

This is the equivalent of `setdiff`, but clearer:

```{r subtract}
subtract(fuzzy_set, set_in = "A", not_in = "B", keep = FALSE, name = "A-B")
# Or the opposite B-A, but using the default name:
subtract(fuzzy_set, set_in = "B", not_in = "A", keep = FALSE)
```

Note that here there is also a subtraction of the fuzzy value.

# Sizes

Note that here the size of a set is not fixed:
```{r set_size}
set_size(fuzzy_set)
```

Or an element can be in 0 sets:

```{r element_size}
element_size(fuzzy_set)
```

In this example we can see that it is more probable that the element A is not 
present than the element f being present in one set. 

# Interpretation

Let's dive a bit in the interpretation.

Imagine you have your experiment where you collected data from a sample of cells for each cell (our elements). 
Then you used some program to classify which type of cell it is (delta endothelial, alpha, beta), this are our sets. 
The software returns a score (between 0 and 1) for each type it has, the higher the more confident it is of the assignment, which is our fuzzy value:

```{r cells_0}
sc_classification <- data.frame(
  elements = c("D2ex_1", "D2ex_10", "D2ex_11", "D2ex_12", "D2ex_13", "D2ex_14", 
               "D2ex_15", "D2ex_16", "D2ex_17", "D2ex_18", "D2ex_1", "D2ex_10", 
               "D2ex_11", "D2ex_12", "D2ex_13", "D2ex_14", "D2ex_15", "D2ex_16",
               "D2ex_17", "D2ex_18", "D2ex_1", "D2ex_10", "D2ex_11", "D2ex_12", 
               "D2ex_13", "D2ex_14", "D2ex_15", "D2ex_16", "D2ex_17", "D2ex_18", 
               "D2ex_1", "D2ex_10", "D2ex_11", "D2ex_12", "D2ex_13", "D2ex_14", 
               "D2ex_15", "D2ex_16", "D2ex_17", "D2ex_18"), 
  sets = c("alpha", "alpha", "alpha", "alpha", "alpha", "alpha", "alpha", 
           "alpha", "alpha", "alpha", "endothel", "endothel", "endothel", 
           "endothel", "endothel", "endothel", "endothel", "endothel", 
           "endothel", "endothel", "delta", "delta", "delta", "delta", "delta", 
           "delta", "delta", "delta", "delta", "delta", "beta", "beta", "beta", 
           "beta", "beta", "beta", "beta", "beta", "beta", "beta"), 
  fuzzy = c(0.18, 0.169, 0.149, 0.192, 0.154, 0.161, 0.169, 0.197, 0.162, 0.201, 
            0.215, 0.202, 0.17, 0.227, 0.196, 0.215, 0.161, 0.195, 0.178, 
            0.23, 0.184, 0.172, 0.153, 0.191, 0.156, 0.167, 0.165, 0.184, 
            0.162, 0.194, 0.197, 0.183, 0.151, 0.208, 0.16, 0.169, 0.169, 
            0.2, 0.154, 0.208), stringsAsFactors = FALSE)
head(sc_classification)
```

Our question is which type of cells did we have on the original sample?
We can easily answer this by looking at the relations that have higher confidence of the relationship for each cell.

```{r cells_classification}
sc_classification <- tidySet(sc_classification)
cells_assigned <- sc_classification %>% 
  activate("relations") %>% 
  group_by(elements) %>% 
  filter(fuzzy == max(fuzzy))
cells_assigned
# See how many cells of each type do we have
cells_assigned %>% 
  group_by(sets) %>% 
  count()
```

Now we know which is the cell type most probable for each cell, and how much of each type do we have.
Let's see how many cells of each type we are more likely to get:

```{r cells_subset}
sample_cells <- sc_classification %>% 
  set_size() %>% 
  group_by(sets) %>% 
  filter(probability == max(probability))
sample_cells
```

And we can see that there are `r paste(apply(sample_cells[, 1:2], 1, function(x){paste0(x[2], " ", x[1], " cells,")}), collapse = " ")`. 
But this doesn't make sense, because there must be some cell misclassification: we have only `r nElements(sc_classification)` cells in this example but there are `r sum(sample_cells$size)` cells predicted for these types:
```{r}
nElements(sc_classification) == sum(sample_cells$size)
```
Ideally the predicted number of cells per type and the cells with higher confidence about the type should match. 

We can also look the other way around: How good is the prediction of a cell type for each cell? 

```{r}
cells_type <- sc_classification %>% 
  element_size() %>% 
  group_by(elements) %>% 
  filter(probability == max(probability))
cells_type
```

We can see that for most cells the most probable cell type is not present (we don't know the type of cell), and some cells could be classified in more than 1 cell type.

```{r}
sc_classification %>% 
  element_size() %>% 
  filter(elements == "D2ex_18") %>% 
  arrange(desc(probability))
```

And as we can see it is mostly as likely to be on the three cell types than in none of the cell types present.
